{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "News media bias",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "12YmM7NO0TCc9NOZuHaVoWs6cmK6N5iA6",
      "authorship_tag": "ABX9TyPquvb4ExxlPTMhXRWeO6DG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swahareddy/political_polarisation/blob/master/News_media_bias.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuEd2ljERu2e",
        "colab_type": "text"
      },
      "source": [
        "This project was created in 2020, with BJP in power (for 2nd consecutive time: 2014+2019) at the centre.\n",
        "\n",
        "At time of creation, the leading political issues are the handling of the standoff with China in Ladakh and growing cases of Covid-19 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAAmwgBBEs9N",
        "colab_type": "text"
      },
      "source": [
        "Oversimplifying the scenario into a BJP vs Congress world. These are the twitter accounts I have used to build the corpus.\n",
        "### INC\n",
        "### List of INC spokespersons: [Official](https://https://twitter.com/i/lists/200025713/members)\n",
        "\n",
        "['JM_Scindia', 'RajBabbarMP', '_SandeepDikshit', 'SATAVRAJEEV', 'VijayIndrSingla', 'Meem_Afzal', 'MYaskhi', 'SinghRPN', 'sushmitadevinc', 'dineshgrao', 'plpunia', 'GauravGogoiAsm', 'DrAMSinghvi', 'drajoykumar', 'khushsundar', 'shaktisinhgohil', 'JhaSanjay', 'DeependerSHooda', 'rajeevgowda']\n",
        "### Others\n",
        "['RahulGandhi', 'sunilkjakhar', 'srinivasiyc', 'INCIndiaLive', '', '', '']\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### BJP\n",
        "### List of BJP spokespersons: (Verified accounts)\n",
        "\n",
        "['sambitswaraj', 'ShahnawazBJP', 'NupurSharmaBJP', 'gauravbh', 'GVLNRAO', 'AshwiniBJP', 'NalinSKohli', '', '', '']\n",
        "### Others\n",
        "['BJP4India', 'rammadhavbjp', 'JPNadda', 'BJPLive']\n",
        "\n",
        "Did not include cabinet ministers since their tweets are overwhelmingly about their portfolios and not about the common narrative.\n",
        "\n",
        "---\n",
        "I'd appreaciate suggestions for more accounts to be added. I do want to add the non-official acounts too (i.e. of non politicians who are very sharp and loud about their opinion). But I do not where to start.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0HVeVHeNlgh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "074df541-6d5f-4fcf-88ab-c398ba8d7623"
      },
      "source": [
        "!pip3 install twint\n",
        "import twint\n",
        "\n",
        "c = twint.Config()\n",
        "c.Limit = 50\n",
        "c.Username = \"SATAVRAJEEV\"\n",
        "c.Pandas = True\n",
        "\n",
        "twint.run.Search(c)\n",
        "Tweets_df = twint.storage.panda.Tweets_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: twint in /usr/local/lib/python3.6/dist-packages (2.1.20)\n",
            "Requirement already satisfied: fake-useragent in /usr/local/lib/python3.6/dist-packages (from twint) (0.1.11)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from twint) (4.6.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from twint) (1.0.5)\n",
            "Requirement already satisfied: aiohttp-socks in /usr/local/lib/python3.6/dist-packages (from twint) (0.5.2)\n",
            "Requirement already satisfied: cchardet in /usr/local/lib/python3.6/dist-packages (from twint) (2.1.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.6/dist-packages (from twint) (3.6.2)\n",
            "Requirement already satisfied: aiodns in /usr/local/lib/python3.6/dist-packages (from twint) (2.0.0)\n",
            "Requirement already satisfied: schedule in /usr/local/lib/python3.6/dist-packages (from twint) (0.6.0)\n",
            "Requirement already satisfied: elasticsearch in /usr/local/lib/python3.6/dist-packages (from twint) (7.8.0)\n",
            "Requirement already satisfied: pysocks in /usr/local/lib/python3.6/dist-packages (from twint) (1.7.1)\n",
            "Requirement already satisfied: googletransx in /usr/local/lib/python3.6/dist-packages (from twint) (2.4.2)\n",
            "Requirement already satisfied: geopy in /usr/local/lib/python3.6/dist-packages (from twint) (1.17.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->twint) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->twint) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas->twint) (1.18.5)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp-socks->twint) (19.3.0)\n",
            "Requirement already satisfied: multidict<5.0,>=4.5 in /usr/local/lib/python3.6/dist-packages (from aiohttp->twint) (4.7.6)\n",
            "Requirement already satisfied: idna-ssl>=1.0; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp->twint) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp->twint) (3.7.4.2)\n",
            "Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->twint) (3.0.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->twint) (1.4.2)\n",
            "Requirement already satisfied: chardet<4.0,>=2.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->twint) (3.0.4)\n",
            "Requirement already satisfied: typing; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiodns->twint) (3.7.4.3)\n",
            "Requirement already satisfied: pycares>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from aiodns->twint) (3.1.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from elasticsearch->twint) (2020.6.20)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from elasticsearch->twint) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from googletransx->twint) (2.23.0)\n",
            "Requirement already satisfied: geographiclib<2,>=1.49 in /usr/local/lib/python3.6/dist-packages (from geopy->twint) (1.50)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->twint) (1.15.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.6/dist-packages (from idna-ssl>=1.0; python_version < \"3.7\"->aiohttp->twint) (2.10)\n",
            "Requirement already satisfied: cffi>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pycares>=3.0.0->aiodns->twint) (1.14.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.5.0->pycares>=3.0.0->aiodns->twint) (2.20)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "CRITICAL:root:twint.get:User:'NoneType' object is not subscriptable\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1285991454121304064 2020-07-22 17:33:49 UTC <SATAVRAJEEV> .@nagma_morarji जी आपकी शुभकामना के लिए धन्यवाद। https://twitter.com/nagma_morarji/status/1285898582495645696 …\n",
            "1285990367737913344 2020-07-22 17:29:30 UTC <SATAVRAJEEV> Thank you very much @AslamShaikh_MLA ji for the good wishes and continued support. https://twitter.com/AslamShaikh_MLA/status/1285896892858036224 …\n",
            "1285989097690062849 2020-07-22 17:24:28 UTC <SATAVRAJEEV> @AUThackeray जी आपण दिलेल्या शुभेच्छा बद्दल आपले मनःपूर्वक धन्यवाद. https://twitter.com/AUThackeray/status/1285985375614312454 …\n",
            "1285980047724011523 2020-07-22 16:48:30 UTC <SATAVRAJEEV> हमारे अध्यक्ष .@AjayLalluINC जी आपकी शुभकामना के लिए धन्यवाद। आपका स्नेह सदैव बना रहे। https://twitter.com/ajaylalluinc/status/1285966620712554496 …\n",
            "1285963534631702528 2020-07-22 15:42:53 UTC <SATAVRAJEEV> Thank you so much @KamalKishor_INC ji for the good wishes https://twitter.com/kamalkishor_inc/status/1285960811513442305 …\n",
            "1285959171876118528 2020-07-22 15:25:33 UTC <SATAVRAJEEV> Thank you very much @DrFauziaKhanNCP ji for the warm and inspiring wishes. https://twitter.com/drfauziakhanncp/status/1285956237914370048 …\n",
            "1285953356901437441 2020-07-22 15:02:26 UTC <SATAVRAJEEV> @KunalChoudhary_ जी आपकी शुभकामना के लिए हार्दिक धन्यवाद। https://twitter.com/kunalchoudhary_/status/1285933522834780160 …\n",
            "1285953147966382084 2020-07-22 15:01:36 UTC <SATAVRAJEEV> .@NitinRaut_INC जी आपकी शुभकामना के लिए धन्यवाद। https://twitter.com/nitinraut_inc/status/1285949314854817793 …\n",
            "1285950757099810816 2020-07-22 14:52:06 UTC <SATAVRAJEEV> Thank you very much @santhoshadv ji for the encouraging wishes. https://twitter.com/santhoshadv/status/1285904114983989248 …\n",
            "1285950309152374787 2020-07-22 14:50:20 UTC <SATAVRAJEEV> Thank you very much @CHOTIWALA ji https://twitter.com/chotiwala/status/1285910363280560129 …\n",
            "1285949403811811331 2020-07-22 14:46:44 UTC <SATAVRAJEEV> Thank you very much @Shahnawaz_JK ji for the good wishes. It is possible because of our leader @rahulgandhi ji whose vision is to promote youths. https://twitter.com/shahnawaz_jk/status/1285947722571198468 …\n",
            "1285948452858298373 2020-07-22 14:42:57 UTC <SATAVRAJEEV> Thank you very much @ShashiK_Sharma ji for the good wishes and affection. https://twitter.com/shashik_sharma/status/1285947228260114434 …\n",
            "1285947913990889472 2020-07-22 14:40:49 UTC <SATAVRAJEEV> आपकी शुभकामना के लिए धन्यवाद  .@Chiranjeev_INC जी। https://twitter.com/chiranjeev_inc/status/1285939905307086849 …\n",
            "1285947365073907713 2020-07-22 14:38:38 UTC <SATAVRAJEEV> Thank you so much @AmritaDhawan1 ji for the wishes https://twitter.com/amritadhawan1/status/1285905848993067008 …\n",
            "1285943812120997889 2020-07-22 14:24:31 UTC <SATAVRAJEEV> Thank you very much Dr. @vishwajeetkadam ji for the warm and encouraging words. https://twitter.com/vishwajeetkadam/status/1285882449679880192 …\n",
            "1285942962187235329 2020-07-22 14:21:08 UTC <SATAVRAJEEV> @IYCGujarat के शुभकामना के लिए बहुत - बहुत धन्यवाद। https://twitter.com/iycgujarat/status/1285932047169581061 …\n",
            "1285937781101834240 2020-07-22 14:00:33 UTC <SATAVRAJEEV> Thank you very much @Neerajkundan ji for such warm wishes. https://twitter.com/neerajkundan/status/1285910557829115904 …\n",
            "1285935082994143234 2020-07-22 13:49:49 UTC <SATAVRAJEEV> Thank you so much @satyajeettambe ji for the warm wishes and affection for me. https://twitter.com/satyajeettambe/status/1285919598382968833 …\n",
            "1285934713278889985 2020-07-22 13:48:21 UTC <SATAVRAJEEV> Thank you very much @VikasThakreINC ji for the warm wishes and continued support. https://twitter.com/vikasthakreinc/status/1285926100506251264 …\n",
            "1285930026374795269 2020-07-22 13:29:44 UTC <SATAVRAJEEV> Thank you very much @SaketGokhale ji for the warm wishes. https://twitter.com/saketgokhale/status/1285911041403043840 …\n",
            "1285929260276838401 2020-07-22 13:26:41 UTC <SATAVRAJEEV> Thank you very much Dr. @jitendradehade ji for the good wishes and continued support. https://twitter.com/jitendradehade/status/1285913308059459585 …\n",
            "1285927638951837697 2020-07-22 13:20:15 UTC <SATAVRAJEEV> Thank you very much @Biswaranjaniyc ji for the good wishes. https://twitter.com/biswaranjaniyc/status/1285902594552901634 …\n",
            "1285927113456078848 2020-07-22 13:18:09 UTC <SATAVRAJEEV> आपण दिलेल्या शुभेच्छा बद्दल  @vijaycMT जी आपले मनःपूर्वक धन्यवाद.   आपल्या शुभेच्छा लाखमोलाच्या आहेत. https://twitter.com/vijaycMT/status/1285920086704844800 …\n",
            "1285924116223021057 2020-07-22 13:06:15 UTC <SATAVRAJEEV> Thank you very much @bb_thorat ji for the warm wishes and for the guidance you have always given me. https://twitter.com/bb_thorat/status/1285898705023823872 …\n",
            "1285915053708005376 2020-07-22 12:30:14 UTC <SATAVRAJEEV> धन्यवाद @VarshaEGaikwad ताई.   आपण दिलेल्या शुभेच्छा बद्दल आपले मनःपूर्वक आभार. https://twitter.com/VarshaEGaikwad/status/1285815889078546433 …\n",
            "1285914286687232000 2020-07-22 12:27:11 UTC <SATAVRAJEEV> धन्यवाद @MeDeshmukh जी.  आपण दिलेल्या शुभेच्छा बद्दल आपले मनःपूर्वक आभार. https://twitter.com/MeDeshmukh/status/1285907698098171905 …\n",
            "1285914019543625729 2020-07-22 12:26:08 UTC <SATAVRAJEEV> धन्यवाद @satejp जी.  आपण दिलेल्या शुभेच्छा बद्दल आपले मनःपूर्वक आभार. https://twitter.com/satejp/status/1285849232302198784 …\n",
            "1285910863749148672 2020-07-22 12:13:35 UTC <SATAVRAJEEV> Thank you very much @devendrayadvinc ji for the good wishes. https://twitter.com/devendrayadvinc/status/1285872609091960832 …\n",
            "1285909529444544512 2020-07-22 12:08:17 UTC <SATAVRAJEEV> Thank you very much @Pawankhera ji humble thanks for the confidence you have shown on me. https://twitter.com/pawankhera/status/1285869387891630082 …\n",
            "1285909053030293504 2020-07-22 12:06:23 UTC <SATAVRAJEEV> Thank you very much @srinivasiyc ji for the good wishes. This is beacause of Rahulji.He always promoted youth leadership. https://twitter.com/srinivasiyc/status/1285873071501393921 …\n",
            "1285907307675545600 2020-07-22 11:59:27 UTC <SATAVRAJEEV> Thank you so much @supriya_sule tai for your wishes https://twitter.com/supriya_sule/status/1285868570094694400 …\n",
            "1285883392416870402 2020-07-22 10:24:25 UTC <SATAVRAJEEV> As I take oath as a member of the Rajya Sabha today, I thank Congress President Sonia Gandhiji, Shri @RahulGandhi ji & all INC leaders from Maharashtra for their support. With the blessings of the people of Maharashtra , I promise to deliver on my duties with the utmost sincerity pic.twitter.com/z9MD5jIfZd\n",
            "1285766252062019585 2020-07-22 02:38:57 UTC <SATAVRAJEEV> महाराष्ट्र राज्याचे उपमुख्यमंत्री, प्रशासन आणि संसदीय कामकाजातील दादा माणूस श्री. अजितदादा पवार ह्यांना वाढदिवसाच्या मनापासून शुभेच्छा. @AjitPawarSpeaks pic.twitter.com/88GZNJI0ZO\n",
            "1285416591367327744 2020-07-21 03:29:31 UTC <SATAVRAJEEV> कांग्रेस के वरिष्ठ नेता, महाराष्ट्र काँग्रेस के प्रभारी  @kharge जी को जन्मदिन की हार्दिक शुभकामनाएं और बधाई। ईश्वर से प्रार्थना है कि आपको दीर्घायु और सुखद जीवन प्रदान करें। pic.twitter.com/QtcH0oM9Us\n",
            "1285235494620557313 2020-07-20 15:29:55 UTC <SATAVRAJEEV> विश्व में भारत का स्थान:- कोरोना संक्रमण- 3 नम्बर पर कोरोना जांच- 55 नम्बर पर और विधायक की खरीददारी- नम्बर 1  #मोदी_है_तो_मुमकिन_है।\n",
            "1285159419555180544 2020-07-20 10:27:37 UTC <SATAVRAJEEV> साहब मजबूर के सामने मजबूत हैं,  और मजबूत के सामने मजबूर हैं।  क्या समझे? https://twitter.com/rahulgandhi/status/1285069516502732800 …\n",
            "1285147751513157633 2020-07-20 09:41:15 UTC <SATAVRAJEEV> गुजरात कांग्रेस के कार्यकारी अध्यक्ष, युवा साथी श्री हार्दिक पटेल जी को जन्मदिन की हार्दिक शुभकामनाएं | https://twitter.com/hardikpatel_/status/1285145422030200832 …\n",
            "1285081592453492736 2020-07-20 05:18:21 UTC <SATAVRAJEEV> \"महाभारत का युद्ध 18 दिन में जीता था, कोरोना को 21 दिन में हराएंगे\" - महान भविष्यवक्ता साहब   अब जीत तो दूर हम लगातार खतरनाक स्तर पर जा रहे है। कल आये 40 हजार से ज्यादा मामले, जल्दी ही हम विश्व गुरु बनने वाले है।#मोदी_हैं_तो_मुमकिन_हैं\n",
            "1285069811060371457 2020-07-20 04:31:33 UTC <SATAVRAJEEV> महाराष्ट्र सरकार में मुंबई के पालक मंत्री असलम शेख जी कोरोना संक्रमित हुए हैं। ईश्वर से प्रार्थना है कि शीघ्र उन्हें स्वस्थ करें ताकि जनता की सेवा मे वे पुनः सक्रिय हो सकें। https://twitter.com/aslamshaikh_mla/status/1285053177549602818 …\n",
            "1285066308220936193 2020-07-20 04:17:37 UTC <SATAVRAJEEV> कांग्रेस की वरिष्ठ नेत्री, दिल्ली की #पूर्व_मुख्यमंत्री तथा आधुनिक दिल्ली की शिल्पकार आदरणीय #शीला_दीक्षित जी की पुण्यतिथि पर उन्हें सादर नमन। pic.twitter.com/glrG6sg4h0\n",
            "1284873475824336897 2020-07-19 15:31:23 UTC <SATAVRAJEEV> लगातार जनसेवा और क्षेत्र के लोगों की समस्या का समाधान करने वाले गुजरात कांग्रेस के वरिष्ठ नेता और विधायक श्री निरंजन पटेल जी कोरोना संक्रमित हुए है। ईश्वर से उनके शीघ्र स्वस्थ होने की प्रार्थना करता हूं। pic.twitter.com/dQYRANys5N\n",
            "1284779317407346688 2020-07-19 09:17:13 UTC <SATAVRAJEEV> १९ जुलै १९६९,इंदिराजींनी देशातील १४ प्रमुख शेड्युल्ड बँकांचे राष्ट्रीयकरण केले,देशातील बँकाच्या लोकशाहीकरणाला सुरुवात झाली. ह्याच राष्ट्रीयकृत बँका विद्यमान सरकारच्या धोरणांमुळे अडचणीत असताना इंदिराजींच्या त्या धाडसी निर्णयाचं स्मरण आवश्यक ठरतं #धन्यवादइंदिराजी pic.twitter.com/PiwJAhW73Z\n",
            "1284762561804562432 2020-07-19 08:10:39 UTC <SATAVRAJEEV> विकास अब तूट गया                                   वो भी आठ दिन में .... साहब ने तो पहले ही कहाँ है                                 आत्मनिर्भर बनो......... https://twitter.com/ani/status/490490111721627649 …\n",
            "1284733745669353473 2020-07-19 06:16:08 UTC <SATAVRAJEEV> जागतिक कीर्तीचे शास्त्रज्ञ विश्वाच्या उत्पत्तीसंबंधी स्थिरस्थिती विश्वाचा जगप्रसिद्ध सिद्धांत मांडणारे आणि मराठीतील विज्ञानकथांचे प्रणेते डॉ. जयंत नारळीकर ह्यांचा आज वाढदिवस. जयंत नारळीकर सरांना वाढदिवसाच्या मनापासून शुभेच्छा pic.twitter.com/KOCBy9cgrJ\n",
            "1284732986185838593 2020-07-19 06:13:07 UTC <SATAVRAJEEV> ‘स्वकर्मात व्हावे रत, मोक्ष मिळे हातो हात।’ ‘सावत्याने केला मळा। विठ्ठल देखियला डोळा।’ ऐहिक जीवनात कर्तव्यकर्म करतानाच काया-वाचे-मने ईश्वरभक्ती करत मोक्ष प्राप्त करता येतो, त्यासाठी सर्वसंगपरित्यागाची गरज नाही हे सोदाहरण दाखवणारे संत सावता माळी ह्यांच्या स्मृतीस विनम्र अभिवादन pic.twitter.com/yGvC3Un0Q1\n",
            "1284506399481851906 2020-07-18 15:12:45 UTC <SATAVRAJEEV> आँकड़े छिपा कर सच्चाई से मुंह नही चुरा सकते। भाजपा का गुजरात मॉडल झूठे तथ्यों और संवेदनहीन शासन का स्वरुप था जो आज भी जारी है। हॉर्स ट्रेडिंग छोड़ भाजपा को जनता का जीवन बेहतर बनाना चाहिए न कि सच छिपाना।#भाजपा_की_गर्तव्यवस्था https://twitter.com/brijdoshi/status/1284469944755744768 …\n",
            "1284401392275226630 2020-07-18 08:15:29 UTC <SATAVRAJEEV> आपल्या कीर्तनकलेतून प्रत्यक्ष पांडुरंगाला डोलायला लावणारे, भागवतधर्माची पताका थेट पंजाबापर्यंत घेऊन जाणारे संत नामदेव. 'नाचू कीर्तनाचे रंगी ज्ञानदीप लावू जगी' हेच आयुष्याचे ध्येय मानलेल्या संतशिरोमणीच्या स्मृतीस माझं विनम्र अभिवादन pic.twitter.com/pHbC1rB9a8\n",
            "1284329125595906049 2020-07-18 03:28:19 UTC <SATAVRAJEEV> मदद करने वालों ने एक-एक रुपया  तेरी झोली में डाल दिया साहब !  अब तू दवाई खरीद या विधायक  तेरे जमीर पर निर्भर है....\n",
            "1284324948950089729 2020-07-18 03:11:44 UTC <SATAVRAJEEV> महाराष्ट्रातील कष्टकऱ्यांच्या चळवळीत आणि संयुक्त महाराष्ट्राच्या नवनिर्मितीत अण्णाभाऊ साठे ह्यांचं योगदान अमूल्य आहे. पोवाडे, लोकनाट्य, पदं, गीतांमधून त्यांनी महाराष्ट्रातील शोषित आणि तळागाळातील जनतेच्या आवाजाला ताकद दिली. ह्या लोकशाहीराच्या स्मृतीस विनम्र अभिवादन. pic.twitter.com/jNrSTtvdq8\n",
            "1284099519123124225 2020-07-17 12:15:57 UTC <SATAVRAJEEV> मध्यप्रदेश के गुना में अत्याचार के बाद गुजरात मे इसकी पुनरावृत्ति हुई। गुजरात के बनासकांठा जिले के धानेरा तहसील के रवि गांव के 25 वर्षीय युवक की हत्या हुई। गरीबों पर भाजपा सरकार के अत्याचार को कांग्रेस बर्दास्त नही करेगी। इसकी जांच हो दोषियों को कड़ी सजा हो। https://twitter.com/AmitChavdaINC/status/1284076608949678084 …\n",
            "1284098298245033984 2020-07-17 12:11:06 UTC <SATAVRAJEEV> Our foreign policy, economy, our relation with neighbours  and the timing of Chinese invasion explained by @rahulgandhi ji in a simple way.#TruthWithRahulGandhi https://twitter.com/rahulgandhi/status/1284002386806095872 …\n",
            "1284045741464317953 2020-07-17 08:42:15 UTC <SATAVRAJEEV> एक वर्षांपूर्वी विधानसभा निवडणुकीच्या तोंडावर मा. बाळासाहेब थोरात जी ह्यांनी प्रदेशाध्यक्षपदाची धुरा हाती घेतली. परिस्थिती काहीशी प्रतिकूल होती तरीही संयमान, कुशलतेने त्यांनी निवडणुकीत आणि पुढील घटनाक्रमात संघटना हाताळली. म्हणूनच वर्षपूर्तीच्या मनापासून शुभेच्छा. @bb_thorat https://twitter.com/incmaharashtra/status/1283972490318868480 …\n",
            "1284002664221569025 2020-07-17 05:51:05 UTC <SATAVRAJEEV> जो ऑडियो सामने आये हैं, उससे साफ जाहिर है कि विधायकों की खरीद फरोख्त करने की साजिश की गई है। कांग्रेस को जो जनमत मिला उसका चीरहरण करने का कुत्सित प्रयास किया गया है। भाजपा लोकतंत्र के शव पर अपनी सत्ता स्थापित करना चाहती है। कांग्रेस लोकतन्त्र की हत्या बर्दास्त नही करेगी। https://twitter.com/rssurjewala/status/1283992049151119360 …\n",
            "1283820769865158662 2020-07-16 17:48:18 UTC <SATAVRAJEEV> वादा तो 15 लाख का था, लेकिन ये कौन जानता था कि  ये रुपयों का नही मरीजों का आँकड़ा था।                                              #CoronaSarkar10LakhPaar\n",
            "1283653487931224067 2020-07-16 06:43:35 UTC <SATAVRAJEEV> योजना चांगली आहे आणि आमचे पूर्ण सहकार्य आहेच. फक्त सरकार आघाडीचे आहे याची काळजी लोकांसमोर जाताना सर्वांनीच घ्यायला हवी. येत्या काळात या जाहिरातीत दुरुस्ती होईल अशी आशा. पुन्हा अशी चूक होणार नाही या खात्रीसोबत. pic.twitter.com/kQYnyhlMO1\n",
            "1283650858123591680 2020-07-16 06:33:08 UTC <SATAVRAJEEV> राज्याच्या पहिल्या मुख्य महिला निवडणूक आयुक्त आणि संवेदनशील लेखिका नीला सत्यनारायण ह्यांचं कोरोनामुळे निधन झालं. दांडगा प्रशासकीय अनुभव आणि त्या अनुभवाला शब्दबद्ध करण्यासाठी मिळालेल सरस्वतीचं वरदान असं दुर्मिळ त्यांचं व्यक्तिमत्व. त्यांच्या स्मृतीस विनम्र अभिवादन pic.twitter.com/nk5uodsqWE\n",
            "1283474392098299904 2020-07-15 18:51:55 UTC <SATAVRAJEEV> #MyLeaderRahulGandhi https://www.facebook.com/179725075270/posts/10164185806155271/?vh=e&d=n …\n",
            "1283448994740355072 2020-07-15 17:11:00 UTC <SATAVRAJEEV> I come from a backward district in Maharashtra where I was a Block Samiti , ZP member. Rahul-ji made me an MLA, then the IYC president, then MP and I am now an invitee to the CWC. Congressmen know it is because of Rahul Gandhi. But will media take note? #MyLeaderRahulGandhi pic.twitter.com/wQkTNygwK5\n",
            "1283262884076752896 2020-07-15 04:51:28 UTC <SATAVRAJEEV> विसाव्या शतकाच्या सुरुवातीच्या काळातील मराठी रंगभूमी आणि चित्रपटांतील अभिनेते, गायक आणि नाट्यनिर्माते आणि रंगभूमीवर स्त्रिया अभिनय करीत नसतानाच्या काळात आपल्या हुबेहुब रंगवलेल्या स्त्री-भूमिकांतुन रंगभूमी गाजवणारे नारायण श्रीपाद राजहंस, ऊर्फ बालगंधर्व ह्यांच्या स्मृतीस अभिवादन pic.twitter.com/QN5KbFR83x\n",
            "1283261503949414401 2020-07-15 04:45:59 UTC <SATAVRAJEEV> एक आदर्श शिक्षक, प्राचार्य, विचारवंत, संशोधक, समीक्षक, लेखक, व्याख्याते आणि साहित्य, संस्कृती , इतिहास, समाजकारण, राजकारण ह्या विषयांवर महाराष्ट्राला मार्गदर्शक ठरलेले मराठवाड्याचे सुपुत्र आचार्य नरहर कुरुंदकर ह्यांची आज जयंती. त्यांच्या स्मृतीस माझं विनम्र अभिवादन pic.twitter.com/rlHUeAO62W\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8TSg9mc8Dj_",
        "colab_type": "text"
      },
      "source": [
        "# GCP API Connections:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyry-JRnUDpp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setting up connection with GCP\n",
        "import os\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"/content/drive/My Drive/Colab Notebooks/maybe-well-do-something-d7263a30102e.json\"\n",
        "project_id=\"maybe-well-do-something\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcbqYQUWQe70",
        "colab_type": "text"
      },
      "source": [
        "Translation from a variety of Indian langauages:\n",
        "\n",
        "Bengali, Gujarati, Hindi, Kannada, Malayalam, Marathi, Odia, Punjabi, Tamil, Telugu, Urdu\n",
        "\n",
        "See full list [here](https://https://cloud.google.com/translate/docs/languages)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EaE7Xr_KATd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "outputId": "7e26bdf1-a548-4e78-fdce-5a0025756cf5"
      },
      "source": [
        "# Translates text into the target language.\n",
        "!pip install google.cloud.translate\n",
        "from google.cloud import translate_v2 as translate\n",
        "print(\"Oe\")\n",
        "translate_client = translate.Client()\n",
        "print(\"Oee\")\n",
        "import six\n",
        "def translate_to_en(text):\n",
        "  if isinstance(text, six.binary_type):\n",
        "      text = text.decode('utf-8')\n",
        "  # Text can also be a sequence of strings, in which case this method\n",
        "  # will return a sequence of results for each text.\n",
        "  result = translate_client.translate(\n",
        "      text, target_language='en')\n",
        "\n",
        "  # print(u'Text: {}'.format(result['input']))\n",
        "  # print(u'Translation: {}'.format(result['translatedText']))\n",
        "  # print(u'Detected source language: {}'.format(\n",
        "  #     result['detectedSourceLanguage']))\n",
        "  return (result['translatedText'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting google.cloud.translate\n",
            "  Using cached https://files.pythonhosted.org/packages/0c/f9/484dba1aa2e222c00884c36d323885abb3283dc4bfc6b75acc4fec1de77c/google_cloud_translate-2.0.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from google.cloud.translate) (1.3.0)\n",
            "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from google.cloud.translate) (1.16.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.15.0->google.cloud.translate) (3.12.2)\n",
            "Requirement already satisfied: setuptools>=34.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.15.0->google.cloud.translate) (49.1.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.15.0->google.cloud.translate) (2.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.15.0->google.cloud.translate) (1.52.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.15.0->google.cloud.translate) (2018.9)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.15.0->google.cloud.translate) (1.17.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.15.0->google.cloud.translate) (1.15.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.8.2; extra == \"grpc\" in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.15.0->google.cloud.translate) (1.30.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.15.0->google.cloud.translate) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.15.0->google.cloud.translate) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.15.0->google.cloud.translate) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.15.0->google.cloud.translate) (3.0.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.15.0->google.cloud.translate) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.15.0->google.cloud.translate) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.15.0->google.cloud.translate) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.15.0->google.cloud.translate) (0.4.8)\n",
            "Installing collected packages: google.cloud.translate\n",
            "Successfully installed google.cloud.translate\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/auth/_default.py\u001b[0m in \u001b[0;36m_load_credentials_from_file\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcaught_exc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \"\"\"\n\u001b[0;32m--> 296\u001b[0;31m     return loads(fp.read(),\n\u001b[0m\u001b[1;32m    297\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-449a45bae6aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install google.cloud.translate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtranslate_v2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtranslate_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtranslate_to_en\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/cloud/translate_v2/client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target_language, credentials, _http, client_info, client_options)\u001b[0m\n\u001b[1;32m     80\u001b[0m     ):\n\u001b[1;32m     81\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_language\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_language\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mClient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_http\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_http\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mkw_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"client_info\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclient_info\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/cloud/client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, credentials, _http)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_GOOGLE_AUTH_CREDENTIALS_HELP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcredentials\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_http\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         self._credentials = google.auth.credentials.with_scopes_if_required(\n\u001b[1;32m    134\u001b[0m             \u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSCOPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/auth/_default.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(scopes, request)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchecker\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheckers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchecker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcredentials\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0mcredentials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwith_scopes_if_required\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscopes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/auth/_default.py\u001b[0m in \u001b[0;36m_get_explicit_environ_credentials\u001b[0;34m()\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexplicit_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         credentials, project_id = _load_credentials_from_file(\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menvironment_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCREDENTIALS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         )\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/auth/_default.py\u001b[0m in \u001b[0;36m_load_credentials_from_file\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile_obj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcaught_exc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             new_exc = exceptions.DefaultCredentialsError(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvJzwwP_U3RY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install google.cloud.language\n",
        "from google.cloud import language_v1\n",
        "from google.cloud.language_v1 import enums\n",
        "\n",
        "def sample_analyze_sentiment(text_content):\n",
        "    client = language_v1.LanguageServiceClient()\n",
        "    # Available types: PLAIN_TEXT, HTML\n",
        "    type_ = enums.Document.Type.PLAIN_TEXT\n",
        "\n",
        "    document = {\"content\": text_content, \"type\": type_}\n",
        "    encoding_type = enums.EncodingType.UTF8 # Available values: NONE, UTF8, UTF16, UTF32\n",
        "    try:\n",
        "      response = client.analyze_sentiment(document, encoding_type=encoding_type)\n",
        "      '''\n",
        "      # Get overall sentiment of the input document\n",
        "      print(u\"Document sentiment score: {}\".format(response.document_sentiment.score))\n",
        "      print(\n",
        "          u\"Document sentiment magnitude: {}\".format(\n",
        "              response.document_sentiment.magnitude\n",
        "          )\n",
        "      )\n",
        "      '''\n",
        "\n",
        "      '''\n",
        "      for sentence in response.sentences:\n",
        "          print(u\"Sentence text: {}\".format(sentence.text.content))\n",
        "          print(u\"Sentence sentiment score: {}\".format(sentence.sentiment.score))\n",
        "          print(u\"Sentence sentiment magnitude: {}\".format(sentence.sentiment.magnitude))\n",
        "      '''\n",
        "\n",
        "      # print(u\"Language of the text: {}\".format(response.language))\n",
        "      sentiment_output={'Sentiment_score':response.document_sentiment.score,\n",
        "                        'Sentiment_mag':response.document_sentiment.magnitude,\n",
        "                        'valid_language':1}\n",
        "      # print (sentiment_output)\n",
        "    except:\n",
        "      sentiment_output={'Sentiment_score':'null',\n",
        "                        'Sentiment_mag':'null',\n",
        "                        'valid_language':0}\n",
        "    return sentiment_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySTy7jj_KHDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.cloud import language_v1\n",
        "from google.cloud.language_v1 import enums\n",
        "import pandas as pd\n",
        "\n",
        "def sample_analyze_entity_sentiment(text_content):\n",
        "    client = language_v1.LanguageServiceClient()\n",
        "    type_ = enums.Document.Type.PLAIN_TEXT\n",
        "\n",
        "    language = \"en\"\n",
        "    document = {\"content\": text_content, \"type\": type_, \"language\": language}\n",
        "    encoding_type = enums.EncodingType.UTF8\n",
        "\n",
        "    response = client.analyze_entity_sentiment(document, encoding_type=encoding_type)\n",
        "\n",
        "    list_entity_deets=[]\n",
        "    entity_name=[]\n",
        "    entity_type=[]\n",
        "    entity_salience=[]\n",
        "    sentiment_score=[]\n",
        "    sentiment_magnitude=[]\n",
        "\n",
        "    row_labels=[]\n",
        "    i=1\n",
        "    # Loop through entitites returned from the API\n",
        "    for entity in response.entities:\n",
        "        '''\n",
        "        print(u\"Representative name for the entity: {}\".format(entity.name))\n",
        "        # Get entity type, e.g. PERSON, LOCATION, ADDRESS, NUMBER, et al\n",
        "        print(u\"\\t Entity type: {}\".format(enums.Entity.Type(entity.type).name))\n",
        "        # Get the salience score associated with the entity in the [0, 1.0] range\n",
        "        print(u\"\\t Salience score: {}\".format(entity.salience))\n",
        "        # Get the aggregate sentiment expressed for this entity in the provided document.\n",
        "        '''\n",
        "        sentiment = entity.sentiment\n",
        "        '''\n",
        "        print(u\"\\t Entity sentiment score: {}\".format(sentiment.score))\n",
        "        print(u\"\\t Entity sentiment magnitude: {}\".format(sentiment.magnitude))\n",
        "        \n",
        "        entity_dict={'name': entity.name,\n",
        "                     'type': enums.Entity.Type(entity.type).name,\n",
        "                     'salience': entity.salience,\n",
        "                     'senti_score': sentiment.score,\n",
        "                     'senti_mag': sentiment.magnitude}\n",
        "        print (entity_dict)\n",
        "        '''\n",
        "        entity_name.append(entity.name.lower())\n",
        "        entity_type.append(enums.Entity.Type(entity.type).name)\n",
        "        entity_salience.append(entity.salience)\n",
        "        sentiment_score.append(sentiment.score)\n",
        "        sentiment_magnitude.append(sentiment.magnitude)\n",
        "        \n",
        "        row_labels.append(i)\n",
        "        i=i+1\n",
        "        # Loop over the metadata associated with entity. For many known entities,\n",
        "        # the metadata is a Wikipedia URL (wikipedia_url) and Knowledge Graph MID (mid).\n",
        "        # Some entity types may have additional metadata, e.g. ADDRESS entities\n",
        "        # may have metadata for the address street_name, postal_code, et al.\n",
        "        '''\n",
        "        for metadata_name, metadata_value in entity.metadata.items():\n",
        "            print(u\"{} = {}\".format(metadata_name, metadata_value))\n",
        "        \n",
        "        # Loop over the mentions of this entity in the input document.\n",
        "        # The API currently supports proper noun mentions.\n",
        "        for mention in entity.mentions:\n",
        "            print(u\"Mention text: {}\".format(mention.text.content))\n",
        "            # Get the mention type, e.g. PROPER for proper noun\n",
        "            print(\n",
        "                u\"Mention type: {}\".format(enums.EntityMention.Type(mention.type).name)\n",
        "            )\n",
        "        '''\n",
        "        # list_entity_deets.append(entity_dict)\n",
        "\n",
        "    dict_entity_deets={'Entity Name': entity_name,\n",
        "                  'Entity Type': entity_type,\n",
        "                  'Entity Salience': entity_salience,\n",
        "                  'Entity Senti Score': sentiment_score,\n",
        "                  'Entity Senti Mag': sentiment_magnitude}\n",
        "\n",
        "    entity_senti_df = pd.DataFrame(data=dict_entity_deets, index=row_labels)\n",
        "    # print(dict_entity_deets)\n",
        "    # print(row_labels)\n",
        "    return (entity_senti_df)\n",
        "    # Get the language of the text, which will be the same as\n",
        "    # the language specified in the request or, if not specified,\n",
        "    # the automatically-detected language.\n",
        "    # print(u\"Language of the text: {}\".format(response.language))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdmKxTA_8RPH",
        "colab_type": "text"
      },
      "source": [
        "# Orchestrator:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3vTGgx_4ZSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(Tweets_df.head(10))\n",
        "print(list(Tweets_df.columns))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dU1D3hG94eaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_tagged_accounts(list_accounts_md):\n",
        "  list_accounts=[]\n",
        "  for dict_account in list_accounts_md[1:]:\n",
        "    account=dict_account['username']\n",
        "    list_accounts.append(account)\n",
        "  return(str(list_accounts))\n",
        "\n",
        "def add_tweet_metadata(df, metadata):\n",
        "  l=len(df.index)\n",
        "  # print(l)\n",
        "  # print(df)\n",
        "  df['Original tweet']=row['tweet']\n",
        "  df['Date']=row['date']\n",
        "  df['Timezone']=row['timezone']\n",
        "  df['Place']=row['place']\n",
        "  # print(df)\n",
        "  df['Hashtags']=str(row['hashtags'])\n",
        "  # print(df)\n",
        "  df['Username']=row['username']\n",
        "  df['Name']=row['name']\n",
        "  df['Link']=row['link']\n",
        "  df['Retweet']=row['retweet']\n",
        "  df['Likes']=row['nlikes']\n",
        "  df['Replies']=row['nreplies']\n",
        "  df['Retweets']=row['nretweets']\n",
        "  df['Quoted tweet']=row['quote_url']\n",
        "  df['Retweets']=row['nretweets']\n",
        "  # print(row['reply_to'])\n",
        "  df['Tagged accounts']=get_tagged_accounts(row['reply_to'])\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV_7dT4aQcJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(Tweets_df.head(3))\n",
        "# tweet_list=Tweets_df[\"tweet\"].tolist()\n",
        "\n",
        "pd.set_option('display.max_columns', None)  # or 1000\n",
        "pd.set_option('display.max_rows', None)  # or 1000\n",
        "pd.set_option('display.max_colwidth', 199)  # or 199\n",
        "# pd.describe_option('display')\n",
        "\n",
        "# print (len(tweet_list))\n",
        "all_tweets=[]\n",
        "for index, row in Tweets_df.iterrows():\n",
        "  tweet=row[\"tweet\"]\n",
        "  # print(tweet)\n",
        "  tweet_tr=translate_to_en(tweet)\n",
        "  # if tweet_tr!=tweet:\n",
        "    # print(tweet_tr)\n",
        "  tweet_internal_deets=sample_analyze_entity_sentiment(tweet_tr)\n",
        "  \n",
        "  # print(tweet_internal_deets)\n",
        "  tweet_internal_deets_person=tweet_internal_deets[tweet_internal_deets['Entity Type']=='PERSON']\n",
        "  tweet_internal_deets_location=tweet_internal_deets[tweet_internal_deets['Entity Type']=='LOCATION']\n",
        "  tweet_internal_deets_organisation=tweet_internal_deets[tweet_internal_deets['Entity Type']=='ORGANIZATION'] #.isin[(['PERSON','LOCATION','ORGANIZATION'])]]\n",
        "  frames=[tweet_internal_deets_person, tweet_internal_deets_location, tweet_internal_deets_organisation]\n",
        "  tweet_internal_deets_filtered=pd.concat(frames)\n",
        "  # print(tweet_internal_deets_filtered)\n",
        "\n",
        "  # Add tweet metadata (from twint) to df\n",
        "  df_w_metadata=add_tweet_metadata(tweet_internal_deets_filtered, row)\n",
        "  df_w_metadata['Translated tweet']=tweet_tr\n",
        "  all_tweets.append(df_w_metadata)\n",
        "\n",
        "all_tweets_df=pd.concat(all_tweets)\n",
        "all_tweets_df.sort_values(by=['Entity Senti Score'], inplace=True, ascending=False)\n",
        "print(all_tweets_df.head())\n",
        "print(all_tweets_df.size)\n",
        "\n",
        "# Select all duplicate rows based on one column\n",
        "duplicateRowsDF = all_tweets_df[all_tweets_df.duplicated(['Name'])]\n",
        "# print(\"Duplicate Rows based on a single column are:\", duplicateRowsDF, sep='\\n')\n",
        "print(duplicateRowsDF.size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhLZuXdKH8Ux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# duplicateRowsDF.to_csv(r'Rajeev Satav.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aoe0cnuGafv6",
        "colab_type": "text"
      },
      "source": [
        "### Lemmatizing entity names \n",
        "(Light-handed WordNet to basically plural->singluar)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOW1KTjvZVsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "porter = PorterStemmer()\n",
        "from nltk.stem import LancasterStemmer\n",
        "lancaster=LancasterStemmer()\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "englishStemmer2=SnowballStemmer(\"english\", ignore_stopwords=True)\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "list_entities=duplicateRowsDF['Entity Name'].tolist()\n",
        "# print(list_entities)\n",
        "\n",
        "lancaster_stemmed=[]\n",
        "porter_stemmed=[]\n",
        "snowabll_stemmed=[]\n",
        "wordnet_lemm=[]\n",
        "entity_lower_og=[]\n",
        "\n",
        "for entity in list_entities:\n",
        "  entity_lower_og.append(entity.lower())\n",
        "  lancaster_stemmed.append(lancaster.stem(entity))\n",
        "  porter_stemmed.append(porter.stem(entity))\n",
        "  snowabll_stemmed.append(englishStemmer2.stem(entity))\n",
        "  wordnet_lemm.append(wordnet_lemmatizer.lemmatize(entity))\n",
        "      \n",
        "stemmed_data={'OG Entity':entity_lower_og,\n",
        "              'Wordnet lemmed':wordnet_lemm,\n",
        "              'Snowball stemmed':snowabll_stemmed,\n",
        "              'Lancaster stemmed':lancaster_stemmed,\n",
        "              'Porter stemmed':lancaster_stemmed\n",
        "              }\n",
        "stemmed_df=pd.DataFrame(data=stemmed_data, index=list(range(len(list_entities))))\n",
        "# print (stemmed_df.head()\n",
        "stemmed_df.to_csv(r'stemmed_lemm.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FftImiqFbePT",
        "colab_type": "text"
      },
      "source": [
        "### Group by entity name\n",
        "New senti score = Weighted average (based on magnitude)\n",
        "\n",
        "New senti mag = Sum(mag)\n",
        "\n",
        "New Hashtags, accounts tagged etc = All original ones combined"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMm14EiHbd8H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "og_df = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/Rajeev Satav.csv\")\n",
        "# og_df=data.head(300)\n",
        "print(og_df.columns)\n",
        "print(og_df.shape)\n",
        "# aggregation_functions = {'price': 'sum', 'amount': 'sum', 'name': 'first'}\n",
        "# new_df=og_df.groupby(og_df['Entity Name']).aggregate(aggregation_functions)\n",
        "\n",
        "# new_df = pd.DataFrame(data=None, columns=og_df.columns, index=og_df.index)\n",
        "# print(new_df.shape)\n",
        "unique_entity_names=entity_types=entity_saliences=entity_senti_scores=entity_senti_mags=og_tweets=dates=timezones=places=hashtags=usernames=names=links=RTs=like_counts=reply_counts=retweet_counts=quoted_tweets=tagged_accounts=translated_tweets=[]\n",
        "new_data={'Unique Entity Name':unique_entity_names, \n",
        "          'Entity Type':entity_types, \n",
        "          'Entity Salience':entity_saliences,\n",
        "          'Entity Senti Score':entity_senti_scores, \n",
        "          'Entity Senti Mag':entity_senti_mags, \n",
        "          'Original tweet':og_tweets,\n",
        "          'Date':dates,\n",
        "          'Timezone':timezones, \n",
        "          'Place':places, \n",
        "          'Hashtags':hashtags, \n",
        "          'Username':usernames, \n",
        "          'Name':names, \n",
        "          'Link':links, \n",
        "          'Retweet':RTs,\n",
        "          'Likes':like_counts, \n",
        "          'Replies':reply_counts, \n",
        "          'Retweets':retweet_counts, \n",
        "          'Quoted tweet':quoted_tweets, \n",
        "          'Tagged accounts':tagged_accounts,\n",
        "          'Translated tweet':translated_tweets}\n",
        "'''\n",
        "for index, row in og_df.iterrows(): \n",
        "  if row['Entity Name'] in unique_entity_names:\n",
        "    pass\n",
        "  else:\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "print(new_df.shape)\n",
        "new_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFgxbgzx4UNJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame({'one':['de', None, None], \n",
        "                   'two':['de ditos', 2, 3], \n",
        "                   'three':[4, None, None], \n",
        "                   'foru':[None, None, 9],\n",
        "                   'five':['de', 4, 6]})\n",
        "df.head()\n",
        "# df.where(df['two']==2,inplace=True)\n",
        "# df.replace(to_replace=2, value=\"222\")\n",
        "df.head()\n",
        "# print(type(df.loc[df['two']=='de ditos']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFQJgyBjQPRy",
        "colab_type": "text"
      },
      "source": [
        "* Need to do stemming/ lemmitization of entites\n",
        "* Truncate 'ji' at end of person entity\n",
        "\n",
        "Do these need different treatment? :\n",
        "* Add tagged twitter accounts\n",
        "* Add hashtags"
      ]
    }
  ]
}